LargeBitS
=========

Dynamic Bitset implementation of bit strings in R, via Rcpp, to save on memory, while maintaining efficient comparisons.

One of the problems with bit vector manipulations in R is that the storage model for any of the various package implementations is attrocious.  Running object.size() on a bit vector or an array of bit vectors will show that the object size in R is many times more than the the simple number of bits in the vector -- often 32 times or more!  This is not the fault of the package builders so much as the convenience of running the bit vector creations, manipulations, operations in R requires the use of the type model and hence memory model of R -- namely, one can't easily get down to the level of bits in R.  Dynamic bitset from the C++ boost library creates bit vectors of arbitrary length in the bit space availible to the nearest byte.  Thus, for example an array of 100, 64 bit bit vectors would account for 6400 bits, or 800 bytes of memory, or 200, 32-bit words, or -- naturally, 100, 64-bit words.  The unfortunate trick is to keep these in memory via Rcpp, and not in R representations.  To do that takes reading and writing them from disk anytime one whats to create, manipulate, or compare bit vectors -- which seems a horrible solution.  However, the hit on performance is small compared to the savings in space.  Since the space savings is large, the efficiency is also improved, which makes up for most of the difference between the fastest R bit vector comparisons.  This provides for doing much larger bit vector operations with R, especially if the bit vectors are themselves large -- there are applications where the number of bits in the bit vectors are in the thousands or 10s of thousands for example.
